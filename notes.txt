This is a scratch notes file, where I put notes to clean up or come back to.

Profuse swearing guaranteed.

----------------------------------------------------------------------------

/*
 * TODO: the value types need a common protocol struct to hold function impls for all the operations
 * that are common between them so we don't end up with switch statements everywhere
 *
 * TODO: the instruction types need the same treatment
 */

/*
 * Here begin scratch thoughts that are probably mostly invalid by the time anyone reads them.
 */

// hold a table of Value references to functions and constants defined internally within this function
// this way this function can be hydrated from a CodeUnit once, and have all its inner functions
// hydrated once as well.

// functions should not have 'inner' functions. The bytecode format should require that all functions definittions
// be hoisted to the top level. code that references functions expliclitly by value, and not indirectly, can use
// the mechanism below:

// going from a CodeUnit to a hydrated representation of a function should not result in a code rewrite
// you can avoid a rewrite by having the bytecode say "load the value of this function reference", where the
// reference is mapped in the header of the Fn to an actual object reference to the function in question. This can
// be populated at the time that the Fn is loaded as a value for the first time.

// a big part of my confusion has been conflating function loading with function invocation/execution

// It must be a property of functions that they retain references to the values they explicitly reference
// beyond a given function call, otherwise all these values have to be re-hydrated from the CodeUnit every time...

//};

// there are three concepts I'd like to separate:
// 1. the CodeUnit that is generated for a function
//    - this includes the actual instructions
//    - this also includes source metadata and constants
//    - this should live on the heap, and be gc-able
// 2. the actual value that can be used to invoke that function
//    - this should really be a singleton
//    - this should live on the heap, and be gc-able
//    - this should hold an object reference to its CodeUnit to prevent it from being gc-ed too soon
// 3. the way this value is discovered by code that wants to invoke it
//    - a literal function reference, returned as a value from another function call
//    - a local
//    - a var
// and yet...
// it would be much easier to duplicate the constants into the functions themselves where needed

//;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; Value Spec ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

// In this machine, all values are represented by a 64-bit word.
//
// The leftmost 3 bits are used to encode the following types. The remaining 61
// bits are interpreted on a per-type basis.
//
// :unsigned-int - an overflowable unsigned integer
// :bool         - 0 for false, 1 for true
// :nil          - constant, always 0
// :char         - the lowest 32 bits represent a UTF-16 character
// :object       - interpreted as an unsigned integer, the value is a pointer
//                 offset to dynamically-allocated memory on the heap.
//
// Objects on the heap are represented this way:
//
// [56 bits - total object size in words][8 bits - specific type of object] [...]
//
// Here are the object types:
//
// :char-array (0)   - The first word is an unsigned integer containing the
//                     number of characters in the string. Each subsequent word
//                     contains up to two UTF-16 characters, one in the higher 32
//                     bits and one in the lower 32 bits. This is an optimization
//                     for representing Strings.
//
// :object-array (1) - The first word is an unsigned integer containing the
//                     number of characters in the string. Each subsequent word
//                     contains a value.
//
// :record-type (2)  - Describes the names of the fields in a record, and their
//                     indexes.
//
// :record (3)       - The first word is the Value that describes the record-type
//                     for a record. The rest of the words are values that
//                     describe the record's fields.
//
// :function (5)     - The first word is the number of arguments the function
//                     accepts. The second word is a string value that is the
//                     source code for the function. The remainder of the words
//                     are instructions, which are represented as word singles
//                     or triples: main instruction, arg hint, arg
//

// TODO: how do we represent lists in the virtual machine? are they implemented on-top of arrays/records? (YES)
// TODO: is a function reference represented differently from a lambda?
// TODO: there appears to be no meaningful difference between args and locals within the vm, they are all just locals
// though captured variables are different, since they may get boxed as part of a lambda


/*
 * When the vm is asked to evaluate code, it always evaluates it in the context of a specific namespace. The symbols
 * defined in this namespace form the basis of the evaluation environment. Also part of the environment is
 * pre-allocated space for the locals the code will introduce. Last, the code will require an operand stack to do
 * anything useful, so one is pre-allocated based on the stack usage the code requires.
 *
 * When the vm evaluates code, it expects that the top-level expression will terminate in a `ret` instruction so it
 * will know the result of the expression it evaluated. The compiler must detect that a form is a top-level
 * form and generate this extra instruction as needed.
 */

//F_CONST,   -> I_LOAD_*
//F_IF,      -> I_JMP_IF
//F_LET,     -> I_STORE_LOCAL
//F_DEF,     -> I_DEFINE
//F_ENV_REF, -> I_LOAD_LOCAL
//F_VAR_REF, -> I_LOAD_VAR
//F_FN,     -> defined fns
//F_BUILTIN,
//F_FN_CALL -> I_INVOKE_DYN

/*
 * tryVMEval(vm, code, &result); // the result is a Value, which the caller can then introspect
 *
 * load code into VM as temporary zero-argument function within current namespace
 * invoke function
 * destroy function
 */

/*
 * the virtual machine at minimum needs to have a main method that accepts a file with bytecode as input
 * this file needs a format, which could just be a sequence of sexprs where each one represents either:
 *
 * - a function definition, containing instructions
 * - an expression, which is just a bag of instructions with no
 */

/* notes transcription:
 *
 * What does a VM need to be useful?
 *
 * - It needs to expose access to the runtime from executing bytecode:
 *
 */

/*
 * So I've been thinking about how to proceed with this VM business...
 *
 * I'm thinking of:
 * - doing the full virtual machine
 * - except just using the current ast as an input
 * - and also doing the vm as a repl, where basically you call an API in a single-threaded fashion to evaluate code
 * - there will be a true, command-line repl, but there will also be an API-based repl for the compiler to use
 * - if using the AST verbatim as the instruction format becomes hard, then I'll know how the bytecode should be different
 *   from the AST.
 * - other than the input format, everything else about the internals of the vm should be as if bytecode was fed in
 *   instead of AST forms. this includes the registers, the operations on the registers, and the runtime.
 *
 * *PERHAPS*: I should just do the fucking instruction set and be done with it
 */


/*
 * Thinking about macro expansion
 *
 * I don't want to write an interpreter, as well as a virtual machine and a compiler that compiles to it, just to be
 * able to execute macros at compile time. I'd rather write the compiler/vm and then do incremental compilation to
 * handle executing the macros at compile time.
 *
 * I'd do this by passing in a VM handle to the compiler as a parameter. The compiler can compile all forms, including
 * macros, and load them into the VM as it discovers them. Every form gets macro-expanded as a part of compilation.
 * When the compiler encounters a reference to a macro, it could take the arguments and feed them into a call to the
 * compiled macro inside the VM, and then use the result for compilation.
 *
 * TODO: think about this: one of the benefits of this model is that it allows us to handle resolving Vars with
 * // the actual virtual machine itself, rather than having to duplicate this in the compiler/analyzer itself.
 * // of course, this suggests that the var resolution should perhaps not be done in the analyzer at all...
 * // rather, the VarRef can just be the name of the symbol, unqualified. the compiler can inspect the symbols in
 * // the namespaces and do compile-time resolution based on what it finds in the virtual machine.
 */


// TODO: first, rest, cons
/*
 * loading the first field on an object via an object reference
 * cons - this can work by calling I_NEW
 */

// emit I_DUP so we have two copies of the arg on the stack
// emit I_TYPE_ASSERT to verify value type is a Cons
// emit I_LOAD_FIELD to load the first field from the Cons

// emit I_DUP so we have two copies of the arg on the stack
// emit I_TYPE_ASSERT to verify value type is a Cons
// emit I_LOAD_FIELD to load the second field from the Cons

/*
 * newcons
 * arg1
 * arg0
 */

// emit I_DUP so we have two copies of the second arg on the stack
// emit I_TYPE_ASSERT to verify the second arg's value type is a Cons
// emit I_NEW to create a new cons object
// emit I_DUP1
// emit I_STORE_FIELD to set the cons 'value' field with the first argument
// emit I_DUP1
// emit I_STORE_FIELD to set the cons 'next'field with the second argument

/*

 * the compiler taking knowlege of the record layout of Cons.
 *
 * TODO: are lists builtins the VM supplies, or things that are implemented on top of it?
 */

/*
 * compute pointer value from offset
 * if the pointer points to the new space, skip it (already moved)
 * else if the pointer points to a forwarding pointer
 *   update the root value to point to the new copy
 * else
 *   dereference it
 *   determine its size
 *   copy it to allocptr, increment allocptr
 *   update the root value to point to the new copy
 *   update the old space with a forwarding pointer to the new space
 */

  /*
   * TODO: scanptr requires that objects in the heap be scannable, meaning that they must contain
   * type information, and may as well contain size information too
   *
   * This probably means we need to make a union container for the objects.
   * As an upside, this will make computing object sizes faster. As a downside, it will increase object sizes.
   * We can probably pack both into a 32 or 64-bit word.
   *
   * TODO: port alloc/deref calling code to work with Object struct
   */

  /*
   * iterate over the objects in the new space that need to be scanned, for each:
   *   traverse the value references within, foreach:
   *
   *     compute pointer value from offset
   *     if the pointer points to the new space, skip it (already moved)
   *     else if the pointer points to a forwarding pointer
   *       update the reference value to point to the new copy
   *     else
   *       dereference it
   *       determine its size
   *       copy it to allocptr, increment allocptr
   *       update the root value to point to the new copy
   *       update the old space with a forwarding pointer to the new space
   *
   */

/*
 * if heap has space for allocated value, allocate:
 *   write object at allocPtr
 *   save allocPtr as new value location
 *   increase allocPtr by length of object
 *
 * else
 *   collect
 *   if heap has space for allocated value, allocate
 *   else fail
 */

// TODO: when hydrating a function, determine its fn declaration depth and keep these in a mapping table after hydration is complete
// TODO: while hydrating, keep a growing list of the constant specs and pointers to the values that should reference functions
// TODO: after hydrating, iterate over the unresolved references, match them up by typeIndex

// during analysis
// - grant a unique id to each function
// - within the function, when adding a binding for the function name, use this id for the binding typeIndex
// during compilation
// - include function ids in functions
// - include function ids in constants that reference functions
// during hydration
// - collect a list of function references, along with pointers to their intended value locations, while hydrating a function
// - before completing hydration, resolve any matching references with the function's hydrated value
// - explode if there are any references that the current function can't satisfy, since we don't support closures yet

gc debugging
------------

(ObjectHeader*)((uint64_t )oldHeap + 153 + 140 + 36 + 32)

before gc 1:

    fn(153)
    fn(140) constant is string:293
    str(36) "hi"
    str(32) "x"

after gc 1:

    fn(140) constant is string:293
    fn(153)
    str(36) "hi"
    str(32) "x"


mid gc 2, pre scanptr:

    fn(140): constant is corrupted (nil type plus huge value)
    fn(153): constant is not corrupted


  /*
   * TODO: when we invoke eval here, we get back an expanded expression that has no line numbers associated with it at all
   *
   * Find a way for eval to save the known line numbers.
   * - maybe include them somehow as metadata on the exprs such that when the macro references them, the lines are
   *   preserved
   * - or find a way to match up the expanded form of the exprs to the unexpanded forms and add back the missing
   *   line numbers by passing through some kind of expr object reference id.
   *
   * *Either way, this is going to involve a re-work of the expander.*
   *
   * There might be another way. All the line numbers that apply to a given macro-expansion area already included in
   * the code unit for doing the macro-expansion. That means if the VM wanted, it could look at them and reuse them.
   * The trouble is that these line numbers become invalid because they are based on code-offsets, which will likely
   * be changed by the new macro output.
   *
   * Let's think about this some more:
   * - we would only expect to get line numbers in macro output where a macro emits values that directly correspond 1:1
   *   with code the user wrote. This would only happen when the macro defines an fn?
   *
   * What if thi mostly doesn't matter? line numbers are for the code that was written, not the code that was generated.
   * Shouldn't it be fine to pretend that the line numbers are correct?
   *
   * If an expr A is rewritten into expr B, it should still get the source lines for expr A. We dont need new source
   * lines that are B-specific. But, we do need to know what expresssions in B refer to source lines from A. Which are
   * those? How do we get back partial source lines?
   *
   *
   * X expr -> X constant -> value -> macro-fn -> value -> expr
   */


;; TODO: figure out how to do c interop, to implement things like string concatenation without creating new vm instructions
;;
;; The JNI way involves handing an Env reference as the first parameter to every native c function call.
;; The rest of the parameters correspond to normal function arguments, they are all Value types.
;;
;; Native functions can be modeled with a special type of stack frame and a special object type that we honor as invocable.
;; Invoking a special object type results in the special stack frame. Special objects must be constructed with a dedicated
;; vm instruction. There will be a registry of special objects that are automatically created and defined as procedures
;; on vm initialization.
;;
;; One job of the special stack is to hold references to all the parameters into a c function, so that they are not
;; garbage-collected prematurely. Garbage collection may happen in the middle of a c function, if the c function does
;; something to trigger it such as allocating memory.
;;
;; One of the things to think about is how to accomodate the GC mid-c-function. To ensure that local references to
;; objects survive a GC relocation, we must do like JNI and keep a special reference to the value that isn't the actual
;; value reference itself. This way, c code does not have to be aware of relocations of objects. This also means that
;; c code cannot have direct access to the memory representation of objects. It must all be proxied through the
;; Environment.
;;
;; The environment must be a composite of the actual VM and the specific special stack frame that contains the registry
;; of the object references the c call holds. When a c call obtains a new reference, this registry should be kept
;; up to date. The c call should be able to voluntarily free references it obtains.
;;
;; There may be a need for a feature that copies the entire contents of an object into non-relocatable memory
;; so that a c function can operate on it safely without worrying about relocation.
;;
;; Another question is how would the VM invoke a special function object? Once the special stack frame is set up,
;; how does the actual c code get called? There is a level of dynamic functionality here that requires knowlege of
;; the c calling conventions. Something has to know how to set up the parameters and jump to the function in question.
;; Does this need to be written in assembly?

;;
;; I thought more about this, and concluded that I don't really need a general purpose FFI like RMI. I can get away
;; with a basic mechanism to invoke c functions where each c function has to be aware of gc and explicitly register
;; references it wants to hold


// TODO: when a function definition captures values from its lexical scope, those values are copied from their
// lexical scope into the function object itself. So the compiler needs a way to figure out how to generate
// code that copies these values whenever they are captured.

/*
 * TODO: this can be realized by creating a builtin the vm honors to load a reference to the function currently being executed into the op stack
 * - analyzer detects function self-references by keeping a stack of in-scope fn-calls
 * - analyzer creates function reference forms
 * - the compiler emits I_LOAD_FN_REF instructions
 * - the vm honors I_LOAD_FN_REF by keeping a 'current' fn handle in the Frame
 *
 * New Plan
 *
 * - analyzer adds function names as bindings in the binding stack
 *   - these bindings get a new binding type
 *   - bindings of this type are indexed separately from the locals, such that typeIndex represents the function
 *     definition depth
 *
 * - compiler creates constants and emits I_LOAD_CONSTs based on references to these new bindings
 *
 * - vm hydration has two phases now:
 *   - the current phase where things get allocated
 *   - the new phase where the function reference constants are resolved. two phases are needed because with the
 *     current algo hydration is depth-first recursive, and I'm not eager to change it right now.
 *
 */

/*
 * Here's a question: how does the compiler know how to identify a var?
 *
 * We can store the var name as a constant. But the VarRef needs to have the constant typeIndex for it.
 *
 * Is it important that N references to the same var in the same compilation unit all reference the exact same
 * constant typeIndex when loading the var value? We already do this for locals and arguments.
 *
 * We could, during analysis, give each distinct var its own typeIndex id, and then made each var reference use that
 * typeIndex id, Then, during compilation we could add those as constants. We'd have to either insert these constants
 * first before adding others
 *
 * // TODO: no, this should just be the name
 * // we can compute distinct values here in the compiler. it can keep track of the strings it has seen, and
 * // note which ones have been given a constant typeIndex
 */

// TODO: in the call stack, these fields don't really tell you much about this
// binding other than that it exists, and how it was defined. is this enough?
// --
// also, the captured type isn't terribly helpful, since that isn't a property
// of the environment, but rather a property of the reference itself


/*
 * What the analyzer needs to do:
 *
 * Take in a sequence of expressions from the reader.
 * Determine whether the expressions are valid. Report clear, semantic errors when they are not.
 * Return an enhanced sequence of expressions that can be used to generate virtual machine code.
 *
 * Each expression will be one of the following:
 * - an evaluation whose resulting value is ignored
 * - an ns declaration, which changes how the analyzer interprets subsequent expressions
 * - a define, which adds/modifies var bindings
 * - a sequence of macro expansions that result in one of the other options
 *
 * The special 'ns' form will tell the analyzer what namespace to use to interpret subsequent
 * expressions it encounters. 'ns' can be called repeatedly. By default the namespace is 'user'.
 *
 * All symbols not explicitly namespaced will be tagged with the namespace they appear in.
 *
 * The non-quoted symbols of each expression will be matched with vars imported into the
 * current namespace or environment bindings defined as part of their lexical scope.
 *
 * 'define' adds/modifies var bindings within a namespace. A var is a reference to the
 * evaluated value. A var's value can be changed through repeated calls to 'define' for the
 * same var name.
 *
 * Values
 * ------
 *
 * Values either
 * - express a constant value (string, number, boolean, nil, syntax-quoted symbol, lambda)
 * - refer to a binding from the environment (symbol referencing lexical binding or var)
 *
 * Some symbols represent special forms, and are handled exceptionally:
 *
 * 'if' provides conditional branching.
 * 'let' permits lexically-scoped binding
 * 'fn' creates an anonymous function (a lambda) as a value, which may also capture bindings
 *      from the environment where it is defined (a closure)
 *
 * 'loop' permits general-purpose iteration
 * 'recur' permits iteration through tail recursion, also used by 'loop'
 *
 * Function Application
 * --------------------
 *
 *  Besides the special forms, the first element of any list will be assumed to be an object
 *  that can be invoked as a function, with the rest of the elements in the list interpreted
 *  to be that function's arguments.
 *  - symbols that are bound to vars can resolve to functions
 *  - symbols that are bound to environment bindings can resolve to functions
 *  - some constants (like keywords and collections) can resolve to functions
 *  - lambdas resolve to functions
 *
 *  Builtin Functions
 *  -----------------
 *
 *  Some functions, though not special forms, are not implemented natively in the language. These
 *  are called builtins, and they are needed to implement the internals of the language. These are
 *  first-class functions from the language's perspective.
 *
 */

/*
 * TODO: is this env binding within my local scope, or am I capturing this from a parent scope?
 *
 * you might know this by examining the binding scopes, working backwards until you get to one defined as part of a function definition
 * if you can't resolve this env ref without crossing that boundary, you know you're capturing
 *
 * if you're capturing, then you need to somehow indicate that so the compiler knows to include this captured value
 * as a part of the current closure
 * - you need to identify which value is being captured (by unique binding id)
 *
 * TODO: within a single Form tree, all bindings must have a unique id
 *
 * the compiler will need to identify the need to create closures based on aggregating these captured values for each fn definition
 * the compiler will need to then compute local indexes based on these plus the fn args and all the normally bound locals wthin a function
 *
 *
 *
 * bindings can be defined by
 * - a fn
 * - a let
 *
 * referenced bindings originating from outside a fn definition must be captured as a part of a closure
 *
 * // TODO: bindings must be defined in the Form tree homogenously, so they can be collected by the compiler
 *    and compared to the references that refer to them. This way the compiler can emit code to create closures
 *    as needed.
 *
 * // TODO: frame locals should not be computed based on references, but based on bindings
 */

/*
 * More from notes:
 *
 *
 * Each fn and the root expr get their own binding tables. These tables can be appended to as captured bindings and
 * let bindings are discovered. References within a function use the binding typeIndex to identify them.
 *
 * Also the idea of a stack frame node specifically to represent a top-level expression separate from the idea of a
 * function definition. The function would be additive.
 */

/*
 * (let (a 100)
 *   (fn X ()
 *     (let (b 200)
 *       (fn Y ()      -- we need to emit a closure here, we need to load a and b from their locals
 *         (+ a b))))) -- but a and b are defined as locals in different stack frames
 *                     -- which means a becomes an extra parameter to X, and a and b become extra parameters to Y
 *
 *                     -- the behavior needed is to seek up the binding stack until a can be resolved. each function
 *                     -- boundary that is crossed to resolve a must have a added to the list of bindings that function
 *                     -- captures. this causes the compiler to allocate local space for a in each function's stack frame,
 *                     -- as well as to create the function as a closure to populate the local space
 *
 *                     -- this way, each captured binding (a and b) are resolved into locals within Y
 *
 * The Plan
 * - the analyzer needs a form type to describe lexical bindings uniformly
 *
 * - the analyzer needs to use a single binding stack for an entire analysis run, no longer creating new binding stacks for fn's
 *   - the analyzer needs to drop the idea of 'scopes', and use a simple array stack where each item in the stack is a union of:
 *     - a let binding (includes unique let typeIndex within a function)
 *     - a function reference binding (only one defined per function)
 *     - a function arg binding (includes arg typeIndex within a function)
 *     - a function definition boundary, referencing a FormFn
 *     instead of pushing/popping scopes, the analyzer can save the current stack height, and then pop back down to it
 *     efficiently when it is done with a particular binding scope
 *
 * - the analyzer needs to walk through the binding stack to resolve binding references as it encounters them. it
 *   starts at the top of the stack and keeps moving down until it finds a binding with a matching name, or hits the
 *   bottom of the stack and errors out because the binding reference cannot be resolved
 *
 * - the analyzer must emit a FormEnvRef that identifies which binding it references. bindings are identified by type
 *   and typeIndex. FormEnvRefs can only identify bindings that originate from within a function or top-level code unit.
 *   All indexes are function and ref-type specific. (types are 'fn-capture', 'fn-self-reference', 'fn-arg', 'let')
 *
 * - if a binding reference is resolved, and it originates from outside a function (it is captured), then each
 *   function definition boundary crossed must have the binding added to it as a captured binding.
 *
 * - captured bindings explicitly reference a binding defined in the function definition boundary immediately above
 *   where the function is defined. otherwise, they are identical to regular binding references.
 *
 * - the compiler needs to build a binding lookup table for all bindings in the CodeUnit and all declared functions,
 *   organizing bindings by id.
 *
 * - the compiler, for each code block, (for code units and fn constants)
 *
 *   // TODO it would be nice if the analyzer gave all the bindings a unique id within a function up-front to make this easier
 *   // it would use this id for all the references
 *
 *   - assigns all the bindings defined a storage location from which they can be loaded when
 *     referenced. these storage locations are stored in a binding table
 *     - function-name bindings have values that are stored as constants
 *     - let-bindings have values that are stored as locals
 *
 *   - when the compiler encounters a binding reference
 *     - if the binding reference refers to a function by name, create a fn-ref-const and emit a LOAD_CONST
 *     - if the binding reference refers to a binding created within the local code scope, emit a LOAD_LOCAL. locals
 *       are referenced by typeIndex. these indexes must be computed
 *
 *   - the compiler should traverse
 *
 *   - the compiler should collect a list of all the captured bindings
 *     if there are one or more captures, the function declaration should be wrapped in a call to the vm to create a closure
 *
 *   - the compiler should build a locals table, and assign locally-defined bindings into it
 *
 *   - the compiler should emit LOADS and STOREs for locals based on the values in this table
 *   - the compiler should emit a LOAD_CONST wherever function references are encountered
 */


  // create an exception
  // - allocate it
  // - set its payload with the error message
  // - initialize its stack trace information
  // - the entire exception is just lists of lists (payload, trace)
  // walk up the stack until we find an error handler
  // if no error handler is found, print the stack trace and goto failure
  // if an error handler is found
  // - pop the stack until the frame with the error handler is the current frame
  // - set the exception as the local index for the handler's exception binding
  // - jump to the error handler's jump address

  /*
   * TODO: how exception handling should work, revised
   * - analyzer defines a try/catch form, where the catch introduces a binding in the binding table + some forms to eval
   * - compiler computes the jumpAddress for the catch block
   * - compiler emits I_SET_HANDLER with 2 index parameters (jumpAddress and exceptionLocalIndex)
   * - vm makes use of error handlers *here* as needed
   *
   * this means no need for lambda/closure execution at error handling time
   */



























